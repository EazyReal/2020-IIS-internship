{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1 - Code Study Allennlp + DataReader, SparseAdjacencyField\n",
    "- 8/?-8/?\n",
    "- code study allennlp (across stages)\n",
    "    - study tools and resources\n",
    "        - allennlp guide\n",
    "        - allennlp doc\n",
    "        - allennlp github (source code)\n",
    "        - google\n",
    "    - data\n",
    "        - fields\n",
    "        - instances\n",
    "        - batch\n",
    "        - dataset\n",
    "        - vocabulary\n",
    "    - data operator\n",
    "        - reader(to_instance)\n",
    "        - vocab.from_instances\n",
    "        - token_indexer(index_with => token_id)\n",
    "        - dataloader(call batch_tensors in fields)\n",
    "        - embedder(token_id2vec)\n",
    "        - encoder(model part)\n",
    "    - trainer\n",
    "        - trainer\n",
    "        - tensorboard_writer\n",
    "        - config file composition and jsonnet\n",
    "    - general work flow conclusion\n",
    "        - rawdata =reader=> instance (with fields)\n",
    "        - instance =Vocab=> vocab (with namespaces)\n",
    "        - instance =IndexWith=> indexed_instances (TensorDict)\n",
    "        - instances =dataloader(batch_tensors function)=> batch_tensor (TensorDict)\n",
    "        - batch_tensor =model=> logits\n",
    "    - allennlp conclusion\n",
    "        - OOP + dependency injection\n",
    "        - a good coding style\n",
    "        - several robust off-the-shelf models\n",
    "- implementation of datareader\n",
    "    - use utils.doc2graph\n",
    "    - graph2instance\n",
    "- implementation of SparseAdjacencyField\n",
    "    - sparse version of origin AdjacencyField\n",
    "    - modify code (almost all) of allennlp AdjacencyField\n",
    "    - implementation of PytorchGeoData Batching\n",
    "\n",
    "# Stage 2 - Train a naive model (BagofWordPooling) with allennlp train\n",
    "- 8/?-8/?\n",
    "- (start this note when 2->3)\n",
    "- mismatched BERT (use defualt mean)\n",
    "    - use PretrainedTransformerMismatchedIndexer + PretrainedTransformerMismatchedEmbedder\n",
    "    - note that here use BERT without special token\n",
    "    - also \"[ROOT]\" in dependency graph is not special token to BERT is a potential issue\n",
    "- sparse2dense, dense2sparse in tensorop.py\n",
    "    - naive implementation works well without tensor\n",
    "    - fix gradient issue\n",
    "        - learn about leaf node in computatino graph\n",
    "        - inplace operation\n",
    "        - tensor properties\n",
    "        - torch.sparse.Tensor.to_dense() as tf.scatter_nd\n",
    "    - 2020/8/21, can actually use pytorch_scatter, pytorch_sparse...\n",
    "- allennlp train can work with my modules\n",
    "    \n",
    "    \n",
    "# (Now) State 3 - Train A HGNN model (het graph embedding w/o interaction)\n",
    "- due 8/22\n",
    "- add Graph2VecEncoder Registrable\n",
    "- implement HGEN\n",
    "\n",
    "# Stage 4 - Train A HGMN model (het graph matching network (may be final))\n",
    "- due 8/31\n",
    "- add GraphPair2VecEncoder Registrable\n",
    "- implement HGMN\n",
    "\n",
    "# Stage 5 - Validation on ANLI/Q-Test/HAN, Experiments\n",
    "- due 9/15\n",
    "- parse ANLI/HAN\n",
    "- Q-Test generator(This may be required earlier)\n",
    "\n",
    "# Stage 6 - Paper Fixing (due 9/19, EACL due 9/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Work\n",
    "- reader to add bidirectional relation\n",
    "    - add add_edge for simplicity\n",
    "- GraphEMbeddingNet(GraphPair2VecEncoder)\n",
    "    - todo\n",
    "- Config is modified\n",
    "    - remove or transformer embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import utils\n",
    "import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
