{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import utils\n",
    "import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## util\n",
    "import os\n",
    "import logging\n",
    "from argparse import ArgumentParser\n",
    "from tqdm import tqdm_notebook as tqdmnb\n",
    "from tqdm import tqdm as tqdm\n",
    "import pickle\n",
    "import json \n",
    "import jsonlines as jsonl\n",
    "from collections import defaultdict\n",
    "from typing import Iterable, List, Dict, Tuple, Union\n",
    "from pathlib import Path\n",
    "## graph\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "## nn\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch_geometric.data.data import Data\n",
    "## Stanza\n",
    "import stanza\n",
    "from stanza.models.common.doc import Document\n",
    "from stanza.pipeline.core import Pipeline\n",
    "## allennlp model\n",
    "from allennlp_models.structured_prediction.predictors.srl import SemanticRoleLabelerPredictor\n",
    "from allennlp_models.structured_prediction.predictors.biaffine_dependency_parser import BiaffineDependencyParserPredictor\n",
    "from allennlp.predictors.predictor import Predictor #\n",
    "## allennlp\n",
    "from allennlp.data import Token, Vocabulary, Instance\n",
    "from allennlp.data.fields import ListField, TextField, Field\n",
    "from allennlp.data.token_indexers import (\n",
    "    SingleIdTokenIndexer,\n",
    "    TokenCharactersIndexer,\n",
    "    ELMoTokenCharactersIndexer,\n",
    "    PretrainedTransformerIndexer,\n",
    "    PretrainedTransformerMismatchedIndexer,\n",
    ")\n",
    "from allennlp.data import DatasetReader, DataLoader, Instance, Vocabulary, PyTorchDataLoader\n",
    "from allennlp.data.tokenizers import (\n",
    "    CharacterTokenizer,\n",
    "    PretrainedTransformerTokenizer,\n",
    "    SpacyTokenizer,\n",
    "    WhitespaceTokenizer,\n",
    ")\n",
    "from allennlp.modules.seq2vec_encoders import CnnEncoder\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import (\n",
    "    Embedding,\n",
    "    TokenCharactersEncoder,\n",
    "    ElmoTokenEmbedder,\n",
    "    PretrainedTransformerEmbedder,\n",
    "    PretrainedTransformerMismatchedEmbedder,\n",
    ")\n",
    "from allennlp.nn import util as nn_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/2020-IIS-NLU-internship/MNLI/data/MNLI_Stanza/pre_multinli_1.0_dev_mismatched.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_path = config.P_TEST_FILE\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparse_adjacency_field import SparseAdjacencyField as SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygd = Data(edge_index=torch.tensor([[0,1], [1,0]]), edge_attr=[\"e0\", \"e1\"])\n",
    "pygd\n",
    "seqf = TextField([Token(\"v0\"), Token(\"vi\")], token_indexers={\"tokens\":SingleIdTokenIndexer(namespace='tokens')})\n",
    "seqf2 = TextField([Token(\"v2\"), Token(\"vi\"), Token(\"v0\")], token_indexers={\"tokens\":SingleIdTokenIndexer(namespace='tokens')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[3], edge_index=[2, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pygd2 = Data(edge_index=torch.tensor([[0,1, 2], [1,0,2]]), edge_attr=[\"e2\", \"e1\", \"e3\"])\n",
    "pygd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaf = SF(pygd, sequence_field=seqf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaf2 = SF(pygd2, sequence_field=seqf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e483c87dcc64b1d9da50329344f0a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='building vocab', max=2.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab2 = Vocabulary.from_instances(instances=[spaf, spaf2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'edge_labels'}\n"
     ]
    }
   ],
   "source": [
    "#bat = Batch([spaf, spaf2])\n",
    "print(vocab2.get_namespaces())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaf.index(vocab2)\n",
    "spaf2.index(vocab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'edge_attr': tensor([1, 0]), 'edge_index': tensor([[0, 1],\n",
      "        [1, 0]]), 'batch_id': tensor([0., 0.])}\n",
      "{'edge_attr': tensor([2, 0, 3]), 'edge_index': tensor([[0, 1, 2],\n",
      "        [1, 0, 2]]), 'batch_id': tensor([0., 0., 0.])}\n"
     ]
    }
   ],
   "source": [
    "t1 = spaf.as_tensor(spaf.get_padding_lengths())\n",
    "t2 = spaf2.as_tensor(spaf.get_padding_lengths())\n",
    "print(t1, t2, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge_index': tensor([[0, 1, 2, 3, 4, 5, 6],\n",
       "         [1, 0, 3, 2, 4, 6, 5]]),\n",
       " 'edge_attr': tensor([1, 0, 2, 0, 3, 1, 0]),\n",
       " 'batch_id': tensor([0, 0, 1, 1, 1, 2, 2])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt3 = spaf.batch_tensors([t1, t2, t1])\n",
    "bt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sparse_adjacency_field.SparseAdjacencyField at 0x7f81fd4ff530>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaf.empty_field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del reader \n",
    "import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdr = reader.NLI_Graph_Reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb24da80ad846e8acc33028f29a9b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='reading instances', max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dev_set = rdr.read(config.P_DEV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abe2aaf3e5646ff93786e0e97939faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='building vocab', max=9815.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_instances(dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----Vocabulary Statistics----\n",
      "\n",
      "\n",
      "Top 10 most frequent tokens in namespace 'edge_labels':\n",
      "\tToken: punct\t\tFrequency: 32065\n",
      "\tToken: case\t\tFrequency: 30338\n",
      "\tToken: nsubj\t\tFrequency: 29153\n",
      "\tToken: det\t\tFrequency: 28436\n",
      "\tToken: root\t\tFrequency: 20496\n",
      "\tToken: advmod\t\tFrequency: 17098\n",
      "\tToken: amod\t\tFrequency: 16704\n",
      "\tToken: obj\t\tFrequency: 15775\n",
      "\tToken: obl\t\tFrequency: 14845\n",
      "\tToken: compound\t\tFrequency: 13444\n",
      "\n",
      "Top 10 longest tokens in namespace 'edge_labels':\n",
      "\tToken: compound:prt\t\tlength: 12\tFrequency: 1258\n",
      "\tToken: nsubj:pass\t\tlength: 10\tFrequency: 2960\n",
      "\tToken: det:predet\t\tlength: 10\tFrequency: 256\n",
      "\tToken: nmod:npmod\t\tlength: 10\tFrequency: 140\n",
      "\tToken: cc:preconj\t\tlength: 10\tFrequency: 122\n",
      "\tToken: reparandum\t\tlength: 10\tFrequency: 10\n",
      "\tToken: csubj:pass\t\tlength: 10\tFrequency: 7\n",
      "\tToken: nmod:poss\t\tlength: 9\tFrequency: 5120\n",
      "\tToken: acl:relcl\t\tlength: 9\tFrequency: 3045\n",
      "\tToken: discourse\t\tlength: 9\tFrequency: 2649\n",
      "\n",
      "Top 10 shortest tokens in namespace 'edge_labels':\n",
      "\tToken: cc\t\tlength: 2\tFrequency: 9585\n",
      "\tToken: acl\t\tlength: 3\tFrequency: 2750\n",
      "\tToken: cop\t\tlength: 3\tFrequency: 7964\n",
      "\tToken: aux\t\tlength: 3\tFrequency: 9263\n",
      "\tToken: obl\t\tlength: 3\tFrequency: 14845\n",
      "\tToken: obj\t\tlength: 3\tFrequency: 15775\n",
      "\tToken: det\t\tlength: 3\tFrequency: 28436\n",
      "\tToken: list\t\tlength: 4\tFrequency: 57\n",
      "\tToken: iobj\t\tlength: 4\tFrequency: 234\n",
      "\tToken: expl\t\tlength: 4\tFrequency: 1357\n"
     ]
    }
   ],
   "source": [
    "vocab.print_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_set.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_loader = PyTorchDataLoader(dev_set, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dev_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['edge_index', 'edge_attr', 'batch_id'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"g_p\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (gmn.py, line 64)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3331\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-33-b7450210bd4f>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    import model\n",
      "\u001b[0;36m  File \u001b[0;32m\"/work/2020-IIS-NLU-internship/MNLI/src_gmn/model.py\"\u001b[0;36m, line \u001b[0;32m23\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from gmn import GraphMatchingNetwork\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/work/2020-IIS-NLU-internship/MNLI/src_gmn/gmn.py\"\u001b[0;36m, line \u001b[0;32m64\u001b[0m\n\u001b[0;31m    raise ValueError('n_blocks (%s) has to be an integer.' % str(n_blocks))\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.token_embedders import (\n",
    "    Embedding,\n",
    "    TokenCharactersEncoder,\n",
    "    ElmoTokenEmbedder,\n",
    "    PretrainedTransformerEmbedder,\n",
    "    PretrainedTransformerMismatchedEmbedder,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_embedder = PretrainedTransformerMismatchedEmbedder(\n",
    "    model_name=config.TRANSFORMER_NAME,\n",
    "    max_length=None, # concat if over max len (512 for BERT base)\n",
    "    train_parameters=True,\n",
    "    last_layer_only=True,\n",
    "    gradient_checkpointing=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Use this embedder to embed wordpieces given by `PretrainedTransformerMismatchedIndexer`\n",
      "    and to pool the resulting vectors to get word-level representations.\n",
      "\n",
      "    Registered as a `TokenEmbedder` with name \"pretrained_transformer_mismatchd\".\n",
      "\n",
      "    # Parameters\n",
      "\n",
      "    model_name : `str`\n",
      "        The name of the `transformers` model to use. Should be the same as the corresponding\n",
      "        `PretrainedTransformerMismatchedIndexer`.\n",
      "    max_length : `int`, optional (default = `None`)\n",
      "        If positive, folds input token IDs into multiple segments of this length, pass them\n",
      "        through the transformer model independently, and concatenate the final representations.\n",
      "        Should be set to the same value as the `max_length` option on the\n",
      "        `PretrainedTransformerMismatchedIndexer`.\n",
      "    train_parameters: `bool`, optional (default = `True`)\n",
      "        If this is `True`, the transformer weights get updated during training.\n",
      "    last_layer_only: `bool`, optional (default = `True`)\n",
      "        When `True` (the default), only the final layer of the pretrained transformer is taken\n",
      "        for the embeddings. But if set to `False`, a scalar mix of all of the layers\n",
      "        is used.\n",
      "    gradient_checkpointing: `bool`, optional (default = `None`)\n",
      "        Enable or disable gradient checkpointing.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(PretrainedTransformerMismatchedEmbedder.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = transformer_embedder(**batch[\"tokens_p\"][\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['token_ids', 'mask', 'type_ids', 'wordpiece_mask', 'offsets'])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"tokens_p\"][\"tokens\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = batch[\"tokens_p\"][\"tokens\"][\"mask\"]\n",
    "tensor = tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 96, 768])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 96])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense2sparse(input_: torch.Tensor, mask: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    usage: convert dense batch(for non-GNN) to sparse batch (for GNN)\n",
    "    a gather_nd method for pytorch with dimension = 3, 2\n",
    "    \n",
    "    input size = (B, batchN, D), (B,batchN)\n",
    "    ouput size = (allN, D), (allN)\n",
    "    \"\"\"\n",
    "    b, n, d = input_.size()\n",
    "    #out = torch.masked_select(input_.permute(2,0,1), mask)\n",
    "    #out = out.view(-1, d).contiguous()\n",
    "    # this implementation will get incorrect output with ok shape\n",
    "    indices = mask.nonzero()\n",
    "    batch_ids = indices.T[0] # this part is batch ids\n",
    "    #out = input_.select(indices)\n",
    "    out = torch.stack([input_[tuple(idx)] for idx in indices])\n",
    "    return {\"data\": out, \"batch_indices\": batch_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1110, 0.4484, 0.1389, 0.2279, 0.7745],\n",
       "         [0.0316, 0.5599, 0.3165, 0.8426, 0.9533],\n",
       "         [0.0964, 0.7436, 0.2511, 0.2539, 0.8207],\n",
       "         [0.4680, 0.4022, 0.6464, 0.5671, 0.4079]],\n",
       "\n",
       "        [[0.4170, 0.1220, 0.5677, 0.7981, 0.7686],\n",
       "         [0.7430, 0.3347, 0.0648, 0.7354, 0.4881],\n",
       "         [0.0044, 0.9131, 0.5679, 0.1209, 0.2855],\n",
       "         [0.4719, 0.2016, 0.1910, 0.9728, 0.7472]],\n",
       "\n",
       "        [[0.4065, 0.9860, 0.4586, 0.6671, 0.8308],\n",
       "         [0.8376, 0.9169, 0.2192, 0.5063, 0.3067],\n",
       "         [0.0230, 0.9705, 0.5191, 0.9600, 0.5340],\n",
       "         [0.8839, 0.3810, 0.8348, 0.4077, 0.5932]]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True, False],\n",
       "        [False,  True,  True, False],\n",
       "        [ True,  True,  True, False]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': tensor([[0.0316, 0.5599, 0.3165, 0.8426, 0.9533],\n",
       "         [0.0964, 0.7436, 0.2511, 0.2539, 0.8207],\n",
       "         [0.7430, 0.3347, 0.0648, 0.7354, 0.4881],\n",
       "         [0.0044, 0.9131, 0.5679, 0.1209, 0.2855],\n",
       "         [0.4065, 0.9860, 0.4586, 0.6671, 0.8308],\n",
       "         [0.8376, 0.9169, 0.2192, 0.5063, 0.3067],\n",
       "         [0.0230, 0.9705, 0.5191, 0.9600, 0.5340]]),\n",
       " 'batch_indices': tensor([0, 0, 1, 1, 2, 2, 2])}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense2sparse(emb, bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "stp = dense2sparse(tp, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 768]) torch.Size([879])\n"
     ]
    }
   ],
   "source": [
    "print(stp[\"data\"].size(), stp[\"batch_indices\"].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "         2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,\n",
       "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,\n",
       "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "         7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "         8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "         9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17,\n",
       "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "        18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 22,\n",
       "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23,\n",
       "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
       "        23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
       "        26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
       "        26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
       "        27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
       "        27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29,\n",
       "        29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "        29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "        31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31,\n",
       "        31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stp[\"batch_indices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.bincount(stp[\"batch_indices\"]) \n",
    "# may use undeterministic algo in GPU, and also non-linear, consecutive is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7, 19, 30, 33, 13, 42, 15, 47, 48, 23, 38, 20, 87, 13, 96, 10, 11, 42,\n",
      "        22, 32,  9,  8, 17, 24, 13,  9, 30, 41,  6, 25, 16, 33])\n"
     ]
    }
   ],
   "source": [
    "_, seqlens = torch.unique_consecutive(stp[\"batch_indices\"], return_counts=True)\n",
    "print(seqlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, invers = torch.unique_consecutive(stp[\"batch_indices\"], return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([879])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([ torch.tensor(list(range(l))) for l in seqlens ], dim=0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, use scatter inverse_indices\n",
    "\"\"\"\n",
    "y = torch.rand(3, 2, 2)\n",
    "z = torch.rand(3, 2, 2)\n",
    "x = torch.rand(3)\n",
    "mask = x.ge(0.5)\n",
    "\n",
    "# get row indices\n",
    "indices = mask.nonzero().squeeze(1)\n",
    "\n",
    "y[indices] = z[indices]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# care gradient\n",
    "def sparse2dense(input_, batch_indices):\n",
    "    _, seqlens = torch.unique_consecutive(stp[\"batch_indices\"], return_counts=True)\n",
    "    indices_y = torch.cat([ torch.tensor(list(range(l))) for l in seqlens ], dim=0)\n",
    "    indices = torch.cat([batch_indices.unsqueeze(dim=1), indices_y.unsqueeze(dim=1)], dim=1) #ok\n",
    "    \n",
    "    #return {\"data\": out, \"mask\": mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 2])\n",
      "tensor([[ 0,  0],\n",
      "        [ 0,  1],\n",
      "        [ 0,  2],\n",
      "        ...,\n",
      "        [31, 30],\n",
      "        [31, 31],\n",
      "        [31, 32]])\n"
     ]
    }
   ],
   "source": [
    "sparse2dense(stp[\"data\"], stp[\"batch_indices\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
